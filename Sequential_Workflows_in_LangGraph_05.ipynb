{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfx1sXT8tOUrpr9i9IPO+c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Image](https://blog.langchain.com/content/images/2024/01/simple_multi_agent_diagram--1-.png)\n",
        "\n",
        "![Image](https://docs.aws.amazon.com/images/prescriptive-guidance/latest/agentic-ai-patterns/images/workflow-for-prompt-chaining.png)\n",
        "\n",
        "![Image](https://miro.medium.com/v2/resize%3Afit%3A1200/0%2Afmk9z4CULIH1fd9w.png)\n",
        "\n",
        "![Image](https://miro.medium.com/v2/resize%3Afit%3A1400/1%2AoWF9Ag_1R7-E9Xv0odsf7A.png)\n",
        "\n",
        "## Sequential Workflows with LangGraph — Structured Guide\n",
        "\n",
        "This guide presents a clean, end-to-end explanation of how to build **sequential workflows** using LangGraph, progressing from foundational concepts to a multi-step LLM prompt-chaining example. The structure and logic strictly follow the provided source without altering its intent or scope.\n",
        "\n",
        "---\n",
        "\n",
        "## Sequential Workflow Implementation Pattern\n",
        "\n",
        "A **sequential workflow** in LangGraph is a strictly linear pipeline. Each task executes in order, with no branching or parallelism. Regardless of complexity, every LangGraph project adheres to the same **five-step structural pattern**:\n",
        "\n",
        "1. **Define State**\n",
        "   Create a `TypedDict` that represents the shared, persistent memory of the workflow.\n",
        "\n",
        "2. **Define Nodes**\n",
        "   Implement Python functions (nodes) that:\n",
        "\n",
        "   * Accept the current state\n",
        "   * Perform a unit of logic\n",
        "   * Return a *partial update* to the state\n",
        "\n",
        "3. **Build Graph**\n",
        "   Initialize a `StateGraph`, register nodes, and connect them with directed edges.\n",
        "\n",
        "4. **Compile**\n",
        "   Validate and finalize the graph structure.\n",
        "\n",
        "5. **Execute**\n",
        "   Invoke the compiled graph with an initial state.\n",
        "\n",
        "---\n",
        "\n",
        "## Project Workflow: LLM Prompt Chaining\n",
        "\n",
        "The most advanced sequential example in the source is a **Blog Generation Workflow**. Instead of a single prompt, the task is decomposed into multiple LLM steps to improve quality, traceability, and state retention.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. State Definition\n",
        "\n",
        "The state object persists across the entire execution. Outputs generated in early nodes (such as the outline) remain accessible to all downstream nodes, including after execution completes.\n",
        "\n",
        "```python\n",
        "from typing import TypedDict\n",
        "\n",
        "class BlogState(TypedDict):\n",
        "    title: str\n",
        "    outline: str\n",
        "    content: str\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Node Logic\n",
        "\n",
        "Each node is a pure function that:\n",
        "\n",
        "* Reads from the shared state\n",
        "* Calls the LLM\n",
        "* Returns only the fields it updates\n",
        "\n",
        "The second node explicitly depends on the output of the first.\n",
        "\n",
        "```python\n",
        "def create_outline(state: BlogState):\n",
        "    prompt = f\"Generate a detailed outline for a blog on: {state['title']}\"\n",
        "    response = model.invoke(prompt).content\n",
        "    return {\"outline\": response}\n",
        "\n",
        "def create_blog(state: BlogState):\n",
        "    prompt = (\n",
        "        f\"Write a blog for '{state['title']}' \"\n",
        "        f\"using this outline: {state['outline']}\"\n",
        "    )\n",
        "    response = model.invoke(prompt).content\n",
        "    return {\"content\": response}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Graph Construction and Visualization\n",
        "\n",
        "LangGraph uses two built-in **dummy nodes**—`START` and `END`—to define entry and exit points. These nodes are not user-defined logic; they exist to enforce graph structure.\n",
        "\n",
        "```python\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "builder = StateGraph(BlogState)\n",
        "\n",
        "builder.add_node(\"generate_outline\", create_outline)\n",
        "builder.add_node(\"generate_blog\", create_blog)\n",
        "\n",
        "builder.add_edge(START, \"generate_outline\")\n",
        "builder.add_edge(\"generate_outline\", \"generate_blog\")\n",
        "builder.add_edge(\"generate_blog\", END)\n",
        "\n",
        "workflow = builder.compile()\n",
        "```\n",
        "\n",
        "In notebook environments (e.g., Jupyter), the compiled graph can be visually rendered to audit execution flow before runtime.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Execution\n",
        "\n",
        "Invoking the workflow triggers node execution in sequence. The state is incrementally updated and returned in full at the end.\n",
        "\n",
        "```python\n",
        "initial_input = {\"title\": \"The Rise of AI in India\"}\n",
        "final_state = workflow.invoke(initial_input)\n",
        "\n",
        "print(final_state[\"outline\"])\n",
        "print(final_state[\"content\"])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Core Benefits of This Structure\n",
        "\n",
        "* **State Persistence**\n",
        "  Intermediate outputs are preserved throughout execution, unlike traditional one-shot chains.\n",
        "\n",
        "* **Observability**\n",
        "  The explicit graph structure allows visual inspection and logical validation before execution.\n",
        "\n",
        "* **Separation of Concerns**\n",
        "  Each node performs exactly one responsibility, simplifying debugging, iteration, and extension.\n",
        "\n",
        "---\n",
        "\n",
        "## Next Logical Extension\n",
        "\n",
        "A natural extension of this sequential workflow is the addition of a third node—such as an **Evaluator**—that consumes the generated blog content and produces a quality score or critique, further enriching the state without altering the linear execution model.\n"
      ],
      "metadata": {
        "id": "zweFNeeR3_5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```python\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_community.llms import HuggingFaceHub\n",
        "from typing import TypedDict\n",
        "import os\n",
        "\n",
        "# Hugging Face token must be set\n",
        "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_xxx\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Model (Free Hugging Face)\n",
        "\n",
        "```python\n",
        "model = HuggingFaceHub(\n",
        "    repo_id=\"google/flan-t5-large\",\n",
        "    model_kwargs={\n",
        "        \"temperature\": 0.3,\n",
        "        \"max_new_tokens\": 512\n",
        "    }\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## State Definition (unchanged style)\n",
        "\n",
        "```python\n",
        "class BlogState(TypedDict):\n",
        "    title: str\n",
        "    outline: str\n",
        "    content: str\n",
        "    score: str\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Node 1 — Create Outline (same pattern)\n",
        "\n",
        "```python\n",
        "def create_outline(state: BlogState) -> BlogState:\n",
        "    title = state[\"title\"]\n",
        "\n",
        "    prompt = f\"Generate a detailed outline for a blog on the topic - {title}\"\n",
        "    outline = model.invoke(prompt)\n",
        "\n",
        "    state[\"outline\"] = outline\n",
        "    return state\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Node 2 — Create Blog (same pattern)\n",
        "\n",
        "```python\n",
        "def create_blog(state: BlogState) -> BlogState:\n",
        "    title = state[\"title\"]\n",
        "    outline = state[\"outline\"]\n",
        "\n",
        "    prompt = (\n",
        "        f\"Write a detailed blog on the title - {title} \"\n",
        "        f\"using the following outline:\\n{outline}\"\n",
        "    )\n",
        "\n",
        "    content = model.invoke(prompt)\n",
        "\n",
        "    state[\"content\"] = content\n",
        "    return state\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ➕ Node 3 — Evaluate Blog (NEW)\n",
        "\n",
        "```python\n",
        "def evaluate_blog(state: BlogState) -> BlogState:\n",
        "    content = state[\"content\"]\n",
        "\n",
        "    prompt = (\n",
        "        \"Evaluate the following blog on a scale of 1 to 10 \"\n",
        "        \"based on clarity, structure, and completeness. \"\n",
        "        \"Also give 1–2 lines of feedback.\\n\\n\"\n",
        "        f\"{content}\"\n",
        "    )\n",
        "\n",
        "    evaluation = model.invoke(prompt)\n",
        "\n",
        "    state[\"score\"] = evaluation\n",
        "    return state\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Graph Construction (same as yours)\n",
        "\n",
        "```python\n",
        "graph = StateGraph(BlogState)\n",
        "\n",
        "graph.add_node(\"create_outline\", create_outline)\n",
        "graph.add_node(\"create_blog\", create_blog)\n",
        "graph.add_node(\"evaluate_blog\", evaluate_blog)\n",
        "\n",
        "graph.add_edge(START, \"create_outline\")\n",
        "graph.add_edge(\"create_outline\", \"create_blog\")\n",
        "graph.add_edge(\"create_blog\", \"evaluate_blog\")\n",
        "graph.add_edge(\"evaluate_blog\", END)\n",
        "\n",
        "workflow = graph.compile()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Execution (same style)\n",
        "\n",
        "```python\n",
        "initial_state = {\n",
        "    \"title\": \"Rise of AI in India\"\n",
        "}\n",
        "\n",
        "final_state = workflow.invoke(initial_state)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Outputs\n",
        "\n",
        "```python\n",
        "print(\"OUTLINE:\\n\", final_state[\"outline\"])\n",
        "print(\"\\nBLOG:\\n\", final_state[\"content\"])\n",
        "print(\"\\nEVALUATION:\\n\", final_state[\"score\"])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "624eQQd_-bfp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F5H32LVaEdYx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}