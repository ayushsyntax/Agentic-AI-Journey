{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhNYXH2kyj3OdB1xCQPDpR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Image](https://substackcdn.com/image/fetch/%24s_%21DJX0%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cee2652-d401-433c-8b29-0b49c13ce27f_2000x1509.png)\n",
        "\n",
        "![Image](https://cdn.prod.website-files.com/640f56f76d313bbe39631bfd/650f6755ec1eba8db2438a6b_tool%20use.png)\n",
        "\n",
        "![Image](https://substackcdn.com/image/fetch/%24s_%21du7b%21%2Cw_1200%2Ch_600%2Cc_fill%2Cf_jpg%2Cq_auto%3Agood%2Cfl_progressive%3Asteep%2Cg_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06f2cf46-df40-48f9-a798-931222b0f70a_590x592.png)\n",
        "\n",
        "![Image](https://miro.medium.com/1%2AB-xl5kNgpnLld4_xmqJ1bw.png)\n",
        "\n",
        "# From Chatbot to **Agentic AI**: A Practical Blueprint for Tool-Enabled LLMs\n",
        "\n",
        "T\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 1. Architectural Concepts That Make Action Possible\n",
        "\n",
        "To transform an LLM into a system that **perceives and acts**, we structure the flow around three components:\n",
        "\n",
        "---\n",
        "\n",
        "### ‚≠ê A. **ToolNode** ‚Äî The Action Executor\n",
        "\n",
        "A specialized **LangGraph node** that:\n",
        "\n",
        "* Houses all external tools (search, calculator, stock APIs, etc.)\n",
        "* Listens for **tool calls** from the LLM\n",
        "* Executes them, returns structured JSON\n",
        "\n",
        "Tools are not executed inline ‚Äî they are orchestrated.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö° B. **ToolsCondition** ‚Äî Dynamic Route Switch\n",
        "\n",
        "A **conditional edge** that analyzes LLM intent:\n",
        "\n",
        "| LLM Output Pattern                | Action             |\n",
        "| --------------------------------- | ------------------ |\n",
        "| General/factual question          | ‚ûú **End response** |\n",
        "| Task requiring external execution | ‚ûú **ToolNode**     |\n",
        "\n",
        "This prevents unnecessary execution and keeps the graph smart.\n",
        "\n",
        "---\n",
        "\n",
        "### üîÅ C. **ReAct Loop** (Critical UX Pattern)\n",
        "\n",
        "Avoid this:\n",
        "\n",
        "```\n",
        "ChatNode ‚Üí ToolNode ‚Üí End\n",
        "```\n",
        "\n",
        "Why? The user sees raw JSON.\n",
        "\n",
        "Instead use:\n",
        "\n",
        "```\n",
        "ChatNode ‚Üí ToolNode ‚Üí ChatNode ‚Üí End\n",
        "```\n",
        "\n",
        "This loop lets the LLM interpret tool outputs before responding to the user.\n",
        "\n",
        "> **Result:** Structured JSON becomes rich language.\n",
        "\n",
        "---\n",
        "\n",
        "## üåÄ 2. Production Flow (Visual + Sequence)\n",
        "\n",
        "### üéØ User Journey\n",
        "\n",
        "Let‚Äôs walk through an example:\n",
        "\n",
        "**User:** *‚ÄúWhat is Tesla‚Äôs stock price?‚Äù*\n",
        "\n",
        "**System does:**\n",
        "\n",
        "1. LLM parses the question\n",
        "2. LLM signals intention to use stock tool\n",
        "3. System routes to **ToolNode**\n",
        "4. Tool fetches structured data\n",
        "5. Result fed back into LLM\n",
        "6. LLM crafts user-ready message\n",
        "\n",
        "---\n",
        "\n",
        "### üìä Sequence Diagram\n",
        "\n",
        "```mermaid\n",
        "sequenceDiagram\n",
        "    participant U as User\n",
        "    participant C1 as ChatNode (LLM)\n",
        "    participant T as ToolNode\n",
        "    participant C2 as ChatNode (LLM)\n",
        "\n",
        "    U->>C1: Ask for stock price\n",
        "    C1->>T: Execute get_stock_price\n",
        "    T->>C2: {\"ticker\":\"TSLA\",\"price\":323}\n",
        "    C2->>U: \"Tesla is trading at $323.\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üõ† 3. Backend ‚Äî Production-Grade Implementation\n",
        "\n",
        "Here is an implementation using LangGraph and LangChain and ready to deploy.\n",
        "\n",
        "---\n",
        "\n",
        "### üß© Step 1 ‚Äî Define and Register Tools\n",
        "\n",
        "```python\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain_core.tools import tool\n",
        "import requests\n",
        "\n",
        "# CALCULATOR TOOL\n",
        "@tool\n",
        "def calculator(a: int, b: int, operation: str) -> float:\n",
        "    \"\"\"Basic arithmetic operations.\"\"\"\n",
        "    ops = {\"add\": a + b, \"subtract\": a - b,\n",
        "           \"multiply\": a * b, \"divide\": a / b}\n",
        "    return ops.get(operation)\n",
        "\n",
        "# STOCK PRICE TOOL\n",
        "@tool\n",
        "def get_stock_price(ticker: str) -> dict:\n",
        "    \"\"\"\n",
        "    Fetches current stock price.\n",
        "    Replace MOCK with real API in prod.\n",
        "    \"\"\"\n",
        "    # TODO: Replace with AlphaVantage/Polygon call\n",
        "    return {\"ticker\": ticker, \"price\": 323.00}\n",
        "\n",
        "# WEB SEARCH TOOL\n",
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "# COLLECT ALL TOOLS\n",
        "tools = [search, calculator, get_stock_price]\n",
        "\n",
        "# BIND TO LLM\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üèó Step 2 ‚Äî Build the LangGraph\n",
        "\n",
        "```python\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "def chat_node(state):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"chatbot\", chat_node)\n",
        "builder.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "builder.add_edge(START, \"chatbot\")\n",
        "builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
        "builder.add_edge(\"tools\", \"chatbot\")\n",
        "\n",
        "graph = builder.compile(checkpointer=memory)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üßë‚Äçüíª 4. Frontend ‚Äî Clean UX With Streamlit\n",
        "\n",
        "**Problem:** Streaming shows raw tool JSON.\n",
        "\n",
        "**Fix:** Only display messages from the LLM.\n",
        "\n",
        "```python\n",
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "for event in events:\n",
        "    message = event[\"messages\"][-1]\n",
        "    if isinstance(message, AIMessage):\n",
        "        st.write(message.content)\n",
        "```\n",
        "\n",
        "**UX Tip:** Use `st.status()` to show live ‚ÄúRunning search‚Ä¶‚Äù indicators.\n",
        "\n",
        "---\n",
        "\n",
        "## üîç 5. Q&A ‚Äî Common Pitfalls & Best Practices\n",
        "\n",
        "| Question                           | Answer                                                  |\n",
        "| ---------------------------------- | ------------------------------------------------------- |\n",
        "| **Why the second ChatNode?**       | So the LLM can interpret tool data into natural text.   |\n",
        "| **Can tools return complex JSON?** | Yes ‚Äî just ensure the LLM schema understands it.        |\n",
        "| **How to secure API calls?**       | Use TLS1.3+, API key vaults, rate limits, and retries.  |\n",
        "| **What if LLM misroutes?**         | Improve tool intent signatures and conditions in Rules. |\n",
        "| **Local testing?**                 | Use mock tool responses and offline checkpointers.      |\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8Y0xs7sqEdK0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lRrw9lVxEgm7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}