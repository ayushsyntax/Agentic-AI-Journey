{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaOmag+sniwCF0ppeq6Mip"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# LangChain vs LangGraph: Building vs Orchestrating AI Systems\n",
        "\n",
        "![LangChain Architecture](https://python.langchain.com/assets/images/langchain_stack-5f0a3b2eab1f63b9f99fa63b52fbd0f1.png)\n",
        "\n",
        "![LangGraph Architecture](https://langchain-ai.github.io/langgraph/static/langgraph_overview.png)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. The Core Difference\n",
        "\n",
        "LangChain builds **LLM components**.\n",
        "LangGraph **controls execution**.\n",
        "\n",
        "LangChain answers:\n",
        "\n",
        "> What should run?\n",
        "\n",
        "LangGraph answers:\n",
        "\n",
        "> What happens next?\n",
        "\n",
        "---\n",
        "\n",
        "## 2. LangChain Architecture\n",
        "\n",
        "```\n",
        "+------------+\n",
        "|   Input    |\n",
        "+------------+\n",
        "      |\n",
        "      v\n",
        "+------------+\n",
        "|  Prompt    |\n",
        "+------------+\n",
        "      |\n",
        "      v\n",
        "+------------+\n",
        "|    LLM     |\n",
        "+------------+\n",
        "      |\n",
        "      v\n",
        "+------------+\n",
        "|  Output    |\n",
        "+------------+\n",
        "```\n",
        "\n",
        "### Characteristics\n",
        "\n",
        "* Linear execution\n",
        "* No memory between runs\n",
        "* No branching\n",
        "* No recovery\n",
        "* Best for short-lived tasks\n",
        "\n",
        "---\n",
        "\n",
        "## 3. LangGraph Architecture\n",
        "```\n",
        "+-------------------+\n",
        "|   State Store     |\n",
        "+-------------------+\n",
        "          |\n",
        "          v\n",
        "+-------------------+\n",
        "|      Node A       |\n",
        "+-------------------+\n",
        "          |\n",
        "          v\n",
        "+-------------------+\n",
        "|  Decision Logic   |\n",
        "+-------------------+\n",
        "     |          |\n",
        "     v          v\n",
        "+---------+  +----------+\n",
        "| Node B  |  | Human    |\n",
        "|         |  | Approval |\n",
        "+---------+  +----------+\n",
        "     |\n",
        "     v\n",
        "+-------------------+\n",
        "|   Checkpoint      |\n",
        "+-------------------+\n",
        "```\n",
        "\n",
        "### Characteristics\n",
        "\n",
        "* Persistent state\n",
        "* Conditional execution\n",
        "* Pause / resume\n",
        "* Retry support\n",
        "* Long-running workflows\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Core Differences\n",
        "\n",
        "| Feature       | LangChain | LangGraph   |\n",
        "| ------------- | --------- | ----------- |\n",
        "| Execution     | Linear    | Graph-based |\n",
        "| State         | Stateless | Persistent  |\n",
        "| Flow control  | Fixed     | Conditional |\n",
        "| Retry         | Manual    | Built-in    |\n",
        "| Human-in-loop | Hard      | Native      |\n",
        "| Long tasks    | Unsafe    | Safe        |\n",
        "| Observability | Partial   | Full        |\n",
        "\n",
        "---\n",
        "\n",
        "## 5. LangChain Example (Modern, Correct)\n",
        "\n",
        "```python\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        "    timeout=30\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Summarize the following text:\\n{text}\"\n",
        ")\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "result = chain.invoke({\n",
        "    \"text\": \"LangChain enables LLM application development.\"\n",
        "})\n",
        "\n",
        "print(result)\n",
        "```\n",
        "\n",
        "✔ Uses LCEL\n",
        "✔ No deprecated APIs\n",
        "✔ Stateless\n",
        "✔ Clean output\n",
        "\n",
        "---\n",
        "\n",
        "## 6. LangGraph Example (Stateful)\n",
        "\n",
        "```python\n",
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "class State(TypedDict):\n",
        "    input: str\n",
        "    output: str\n",
        "\n",
        "def summarize(state: State):\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "    response = llm.invoke(state[\"input\"])\n",
        "    return {\"output\": response.content}\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"summarize\", summarize)\n",
        "builder.add_edge(START, \"summarize\")\n",
        "builder.add_edge(\"summarize\", END)\n",
        "\n",
        "checkpointer = SqliteSaver.from_conn_string(\"workflow.db\")\n",
        "graph = builder.compile(checkpointer=checkpointer)\n",
        "\n",
        "result = graph.invoke({\n",
        "    \"input\": \"LangGraph supports stateful workflows.\"\n",
        "})\n",
        "\n",
        "print(result[\"output\"])\n",
        "```\n",
        "\n",
        "✔ Stateful\n",
        "✔ Recoverable\n",
        "✔ Replayable\n",
        "✔ Production-ready\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Human-in-the-Loop (Correct Pattern)\n",
        "\n",
        "```python\n",
        "from langgraph.types import interrupt\n",
        "\n",
        "def approval_node(state):\n",
        "    if not state.get(\"approved\"):\n",
        "        interrupt(\"Waiting for human approval\")\n",
        "    return state\n",
        "```\n",
        "\n",
        "Execution halts safely and resumes later without data loss.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Execution Flow Comparison\n",
        "\n",
        "### LangChain\n",
        "\n",
        "```\n",
        "Start → Run → Finish\n",
        "```\n",
        "\n",
        "### LangGraph\n",
        "\n",
        "```\n",
        "Start → Node → Decision\n",
        "             ↓\n",
        "         Pause / Retry\n",
        "             ↓\n",
        "          Continue\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 9. When to Use What\n",
        "\n",
        "### Use LangChain when:\n",
        "\n",
        "* Flow is linear\n",
        "* No retries needed\n",
        "* Short-lived execution\n",
        "* Simple RAG or chatbot\n",
        "\n",
        "### Use LangGraph when:\n",
        "\n",
        "* Workflow branches\n",
        "* Human approval exists\n",
        "* Tasks are long-running\n",
        "* State must persist\n",
        "* You are building agents\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Final Takeaway\n",
        "\n",
        "LangChain builds **capabilities**.\n",
        "LangGraph controls **behavior**.\n",
        "\n",
        "LangChain is the engine.\n",
        "LangGraph is the control system.\n",
        "\n",
        "If your AI system must think, wait, retry, or decide —\n",
        "LangGraph is no longer optional.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "54rKZiP96hpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangChain vs. LangGraph: Architectural Clarity for AI Workflows  \n",
        "\n",
        "LangChain and LangGraph are two essential tools for building AI applications, but they serve different roles in the development process. LangChain is an open-source library designed to simplify building LLM-based applications by providing modular building blocks. LangGraph is an orchestration framework built on top of LangChain to manage stateful, multi-step, and non-linear workflows.  \n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Core Architectural Differences**  \n",
        "- **LangChain (Linear Chains)**:  \n",
        "  Primarily designed for linear workflows where the output of one block becomes the input for the next. While it handles simple conversational flows well, it struggles with complex, non-linear logic.  \n",
        "- **LangGraph (Stateful Graphs)**:  \n",
        "  Represents a workflow as a **graph**. Each task is a **node** (a Python function), and the execution path is defined by **edges**. This structure natively supports loops, conditional branching, and jumps without requiring \"glue code\".  \n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Deep Dive into the Seven Key Challenges**  \n",
        "\n",
        "| Feature               | LangChain                                                                 | LangGraph                                                                 |\n",
        "|-----------------------|---------------------------------------------------------------------------|---------------------------------------------------------------------------|\n",
        "| **Control Flow**      | Best for linear chains; non-linear logic (loops/jumps) requires excessive manual Python \"glue code\". | Natively supports non-linear logic (loops, branches) through its graph-based engine. |\n",
        "| **State Management**  | **Stateless.** It does not have an intrinsic mechanism to track and update complex data points across a multi-step workflow. | **Stateful.** It uses a shared state object (like a dictionary) that every node can read from and write to, allowing the system to evolve over time. |\n",
        "| **Execution Style**   | **Sequential.** Once a chain starts, it typically runs to completion without stopping. | **Event-Driven.** It can pause execution to wait for an external trigger or a specific time delay before resuming. |\n",
        "| **Fault Tolerance**   | Lacks built-in recovery; if a chain fails at step 5, the entire process must usually restart from step 1. | Features built-in **retry logic** and **recovery**. It uses \"checkpointers\" to save snapshots of the state after every node, allowing it to resume exactly where it failed. |\n",
        "| **Human-in-the-Loop** | Difficult to implement for long-running tasks. Pausing for human approval (e.g., for 24 hours) often leads to resource waste or crashes. | A \"first-class citizen.\" The system can pause indefinitely and resume once human input is received, persisting the context in the meantime. |\n",
        "| **Nested Workflows**  | Not natively supported within the \"chain\" abstraction.                  | Supports **subgraphs**, where a single node can be an entire separate graph. This enables **multi-agent systems** and **reusable workflows**. |\n",
        "| **Observability**     | Provides **partial observability** via LangSmith; it tracks LangChain components but cannot monitor the custom \"glue code\". | Provides **complete observability**. Every state change and decision point is recorded chronologically in LangSmith for debugging and auditing. |\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Strategic Guidance: When to Use What**  \n",
        "- **Use LangChain** for simple, linear tasks such as:  \n",
        "  - Basic text summarizers  \n",
        "  - Single-turn chatbots  \n",
        "  - Standard Retrieval-Augmented Generation (RAG) systems  \n",
        "- **Use LangGraph** for complex, \"agentic\" applications that require:  \n",
        "  - Autonomy and iterative loops  \n",
        "  - Multi-agent collaboration  \n",
        "  - Workflows needing human intervention pauses  \n",
        "\n",
        "---\n",
        "\n",
        "#### **4. The Synergy Between Tools**  \n",
        "LangGraph does not replace LangChain; it is built on top of it. While LangGraph handles the **orchestration** (the \"how\" of the workflow), LangChain still provides the **components**—such as model interfaces, prompt templates, and document loaders—that live inside the graph's nodes.  \n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "C0NHdRuB-Edg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zRqptrdz6lGh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}