{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz+csztEyuie+CjWWTzeV+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Iterative (Looping) Workflows in LangGraph\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Concept Overview\n",
        "\n",
        "Iterative workflows differ from linear or parallel workflows by allowing **repeated execution of nodes** until a quality condition is satisfied or a hard stop is reached.\n",
        "In LangGraph, iteration is implemented using **conditional edges** combined with **loop-back edges**.\n",
        "\n",
        "Core properties:\n",
        "\n",
        "* Deterministic control flow\n",
        "* Explicit termination conditions\n",
        "* State-driven evaluation\n",
        "* No implicit retries\n",
        "\n",
        "Primary goal: **progressive quality improvement through evaluation-feedback loops**.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Use Case: Automated Tweet Generation\n",
        "\n",
        "Target platform: Twitter/X\n",
        "Problem addressed: LLM-generated tweets are often generic or low-impact.\n",
        "\n",
        "Solution: A **three-node iterative loop**:\n",
        "\n",
        "1. Generate → create candidate tweet\n",
        "2. Evaluate → strict quality judgment\n",
        "3. Optimize → rewrite based on feedback\n",
        "\n",
        "The loop continues until:\n",
        "\n",
        "* The tweet is approved, **or**\n",
        "* `max_iteration` is reached\n",
        "\n",
        "---\n",
        "\n",
        "## 3. High-Level Architecture\n",
        "\n",
        "![Image](https://miro.medium.com/v2/resize%3Afit%3A1200/1%2AWK2y_TTKVa0bxbC_A11tWw.png)\n",
        "\n",
        "![Image](https://images.squarespace-cdn.com/content/v1/6508aa0576c883057e96d23c/415ab2a4-782d-458c-b45f-000ed0c34f62/16%2BSystems%2BDesign%2C%2Bor%2BHow%2Bto%2BMake%2BLLMs%2BPart%2Bof%2Ba%2BFeedback%2BLoop%2B%282%29.png)\n",
        "\n",
        "![Image](https://www.researchgate.net/profile/Rania-Khalaf/publication/37685567/figure/fig2/AS%3A394256666644492%401471009522682/State-transition-Diagram-Loops-Description-of-events.png)\n",
        "\n",
        "Components:\n",
        "\n",
        "* **StateGraph**: Controls execution\n",
        "* **Typed State**: Shared memory across nodes\n",
        "* **Reducer functions**: Preserve historical data\n",
        "* **Conditional routing**: Governs looping behavior\n",
        "\n",
        "---\n",
        "\n",
        "## 4. State Definition\n",
        "\n",
        "The state is the **single source of truth** for the workflow.\n",
        "\n",
        "Key design decisions:\n",
        "\n",
        "* Use `TypedDict` for static guarantees\n",
        "* Use `Annotated[..., operator.add]` to append history instead of overwriting\n",
        "* Track iteration explicitly to prevent infinite loops\n",
        "\n",
        "```python\n",
        "from typing import TypedDict, List, Annotated, Literal\n",
        "import operator\n",
        "\n",
        "class TweetState(TypedDict):\n",
        "    topic: str\n",
        "    tweet: str\n",
        "    evaluation: Literal[\"approved\", \"needs_improvement\"]\n",
        "    feedback: str\n",
        "    iteration: int\n",
        "    max_iteration: int\n",
        "\n",
        "    tweet_history: Annotated[List[str], operator.add]\n",
        "    feedback_history: Annotated[List[str], operator.add]\n",
        "```\n",
        "\n",
        "State invariants:\n",
        "\n",
        "* `iteration <= max_iteration`\n",
        "* `tweet_history[i]` corresponds to `feedback_history[i-1]`\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Node Responsibilities\n",
        "\n",
        "![Image](https://dist.neo4j.com/wp-content/uploads/20240618104511/build-kg-genai-e1718732751482.png)\n",
        "\n",
        "![Image](https://miro.medium.com/1%2ABR5ProfeqWPQTZnUB_pTuw.png)\n",
        "\n",
        "![Image](https://substackcdn.com/image/fetch/%24s_%21cBRs%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1ccc0c4-b5f2-4b02-91b3-ea5bc54cd8c0_1687x993.png)\n",
        "\n",
        "### 5.1 Generate Node\n",
        "\n",
        "Purpose:\n",
        "\n",
        "* Produce the **initial tweet** from topic input\n",
        "\n",
        "Characteristics:\n",
        "\n",
        "* High creativity\n",
        "* No evaluation logic\n",
        "* Appends to `tweet_history`\n",
        "\n",
        "```python\n",
        "def generate_tweet(state: TweetState):\n",
        "    messages = [\n",
        "        SystemMessage(content=\"You are a funny and clever Twitter/X influencer.\"),\n",
        "        HumanMessage(content=f\"\"\"\n",
        "Write a short, original, and hilarious tweet on the topic: \"{state['topic']}\".\n",
        "\n",
        "Rules:\n",
        "- Do NOT use question-answer format.\n",
        "- Max 280 characters.\n",
        "- Use observational humor, irony, sarcasm, or cultural references.\n",
        "- Think in meme logic, punchlines, or relatable takes.\n",
        "- Use simple, day to day english\n",
        "\"\"\")\n",
        "    ]\n",
        "\n",
        "    response = generator_llm.invoke(messages).content\n",
        "    return {\"tweet\": response, \"tweet_history\": [response]}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 5.2 Evaluate Node (Structured Output)\n",
        "\n",
        "Purpose:\n",
        "\n",
        "* Enforce **objective quality gates**\n",
        "* Return **machine-readable decisions**\n",
        "\n",
        "Key technique:\n",
        "\n",
        "* Pydantic schema + `with_structured_output`\n",
        "\n",
        "```python\n",
        "class TweetEvaluation(BaseModel):\n",
        "    evaluation: Literal[\"approved\", \"needs_improvement\"]\n",
        "    feedback: str\n",
        "```\n",
        "\n",
        "Evaluation guarantees:\n",
        "\n",
        "* No free-form parsing\n",
        "* Deterministic routing\n",
        "* Hard auto-reject rules enforced\n",
        "\n",
        "```python\n",
        "def evaluate_tweet(state: TweetState):\n",
        "    response = structured_evaluator_llm.invoke(messages)\n",
        "    return {\n",
        "        \"evaluation\": response.evaluation,\n",
        "        \"feedback\": response.feedback,\n",
        "        \"feedback_history\": [response.feedback]\n",
        "    }\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 5.3 Optimize Node\n",
        "\n",
        "Purpose:\n",
        "\n",
        "* Rewrite tweet using **specific critic feedback**\n",
        "* Increment iteration counter\n",
        "\n",
        "```python\n",
        "def optimize_tweet(state: TweetState):\n",
        "    response = optimizer_llm.invoke(messages).content\n",
        "    iteration = state[\"iteration\"] + 1\n",
        "\n",
        "    return {\n",
        "        \"tweet\": response,\n",
        "        \"iteration\": iteration,\n",
        "        \"tweet_history\": [response]\n",
        "    }\n",
        "```\n",
        "\n",
        "Constraints:\n",
        "\n",
        "* Must stay under 280 characters\n",
        "* Must not introduce Q&A format\n",
        "* Must directly address feedback text\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Routing Logic (Termination Control)\n",
        "\n",
        "![Image](https://miro.medium.com/1%2AbwFI898xU8OA1woG1FDuZA.png)\n",
        "\n",
        "![Image](https://corporate-assets.lucid.co/chart/91f7e59b-6c97-4f0f-a808-81ccb2e89a75.jpeg?v=1707842463172)\n",
        "\n",
        "Routing is implemented as a **pure function** (not a node).\n",
        "\n",
        "```python\n",
        "def route_evaluation(state: TweetState):\n",
        "    if state[\"evaluation\"] == \"approved\" or state[\"iteration\"] >= state[\"max_iteration\"]:\n",
        "        return \"approved\"\n",
        "    return \"needs_improvement\"\n",
        "```\n",
        "\n",
        "Properties:\n",
        "\n",
        "* Side-effect free\n",
        "* Deterministic\n",
        "* Prevents infinite loops\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Graph Construction\n",
        "\n",
        "![Image](https://substackcdn.com/image/fetch/%24s_%21jnzp%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1eca5d1-0462-4833-ae12-7b645a4e3a20_1828x876.png)\n",
        "\n",
        "![Image](https://miro.medium.com/1%2AbwFI898xU8OA1woG1FDuZA.png)\n",
        "\n",
        "```python\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "builder = StateGraph(TweetState)\n",
        "\n",
        "builder.add_node(\"generate\", generate_tweet)\n",
        "builder.add_node(\"evaluate\", evaluate_tweet)\n",
        "builder.add_node(\"optimize\", optimize_tweet)\n",
        "\n",
        "builder.add_edge(START, \"generate\")\n",
        "builder.add_edge(\"generate\", \"evaluate\")\n",
        "\n",
        "builder.add_conditional_edges(\n",
        "    \"evaluate\",\n",
        "    route_evaluation,\n",
        "    {\n",
        "        \"approved\": END,\n",
        "        \"needs_improvement\": \"optimize\"\n",
        "    }\n",
        ")\n",
        "\n",
        "builder.add_edge(\"optimize\", \"evaluate\")\n",
        "\n",
        "graph = builder.compile()\n",
        "```\n",
        "\n",
        "Graph semantics:\n",
        "\n",
        "* `evaluate` is the decision point\n",
        "* `optimize → evaluate` forms the loop\n",
        "* `END` is reachable from only one node\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Execution Example\n",
        "\n",
        "Initial state:\n",
        "\n",
        "```python\n",
        "initial_state = {\n",
        "    \"topic\": \"srhberhb\",\n",
        "    \"iteration\": 1,\n",
        "    \"max_iteration\": 5\n",
        "}\n",
        "```\n",
        "\n",
        "Invocation:\n",
        "\n",
        "```python\n",
        "result = workflow.invoke(initial_state)\n",
        "```\n",
        "\n",
        "Observed behavior:\n",
        "\n",
        "* One generation\n",
        "* One evaluation\n",
        "* Approved on first pass\n",
        "* No optimization loop triggered\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Key Implementation Insights\n",
        "\n",
        "* Iterative quality improvement requires **explicit evaluation criteria**\n",
        "* Structured outputs eliminate brittle text parsing\n",
        "* Reducers enable full auditability of model behavior\n",
        "* Loop bounds are mandatory in production systems\n",
        "* Different models per node optimize cost vs. capability\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Mental Model Summary\n",
        "\n",
        "* LangGraph loops are **graph-level constructs**, not Python loops\n",
        "* State evolution is additive, not mutative\n",
        "* Every iteration is observable and replayable\n",
        "* Quality control is enforced structurally, not heuristically\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AC_fS5ekLO9P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vcl3RrplLS4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```bash\n",
        "pip install -U langgraph langchain langchain-openai pydantic\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Import Core Dependencies\n",
        "\n",
        "Purpose:\n",
        "\n",
        "* LangGraph for workflow orchestration\n",
        "* LangChain for LLM abstraction\n",
        "* Pydantic for structured evaluation\n",
        "* TypedDict + reducers for state safety and history tracking\n",
        "\n",
        "```python\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from typing import TypedDict, Literal, Annotated\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from pydantic import BaseModel, Field\n",
        "import operator\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Step 2: Initialize LLMs\n",
        "\n",
        "Design choice:\n",
        "\n",
        "* Same model used for simplicity\n",
        "* Logical separation by role (generator, evaluator, optimizer)\n",
        "\n",
        "```python\n",
        "generator_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "evaluator_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "optimizer_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Step 3: Define Structured Evaluation Output\n",
        "\n",
        "Purpose:\n",
        "\n",
        "* Enforce deterministic routing\n",
        "* Prevent free-text parsing errors\n",
        "\n",
        "```python\n",
        "class TweetEvaluation(BaseModel):\n",
        "    evaluation: Literal[\"approved\", \"needs_improvement\"] = Field(..., description=\"Final evaluation result.\")\n",
        "    feedback: str = Field(..., description=\"feedback for the tweet.\")\n",
        "\n",
        "structured_evaluator_llm = evaluator_llm.with_structured_output(TweetEvaluation)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Step 4: Define Shared State (Graph Memory)\n",
        "\n",
        "Key points:\n",
        "\n",
        "* `Annotated[..., operator.add]` appends history instead of overwriting\n",
        "* Iteration counter prevents infinite loops\n",
        "\n",
        "```python\n",
        "class TweetState(TypedDict):\n",
        "    topic: str\n",
        "    tweet: str\n",
        "    evaluation: Literal[\"approved\", \"needs_improvement\"]\n",
        "    feedback: str\n",
        "    iteration: int\n",
        "    max_iteration: int\n",
        "\n",
        "    tweet_history: Annotated[list[str], operator.add]\n",
        "    feedback_history: Annotated[list[str], operator.add]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Step 5: Generation Node\n",
        "\n",
        "Responsibility:\n",
        "\n",
        "* Produce the first tweet\n",
        "* No evaluation logic\n",
        "* Append tweet to history\n",
        "\n",
        "```python\n",
        "def generate_tweet(state: TweetState):\n",
        "    messages = [\n",
        "        SystemMessage(content=\"You are a funny and clever Twitter/X influencer.\"),\n",
        "        HumanMessage(content=f\"\"\"\n",
        "Write a short, original, and hilarious tweet on the topic: \"{state['topic']}\".\n",
        "\n",
        "Rules:\n",
        "- Do NOT use question-answer format.\n",
        "- Max 280 characters.\n",
        "- Use observational humor, irony, sarcasm, or cultural references.\n",
        "- Think in meme logic, punchlines, or relatable takes.\n",
        "- Use simple, day to day english\n",
        "\"\"\")\n",
        "    ]\n",
        "\n",
        "    response = generator_llm.invoke(messages).content\n",
        "    return {\"tweet\": response, \"tweet_history\": [response]}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Step 6: Evaluation Node (Critic)\n",
        "\n",
        "Responsibility:\n",
        "\n",
        "* Enforce quality gates\n",
        "* Decide approve vs improve\n",
        "* Generate actionable feedback\n",
        "\n",
        "```python\n",
        "def evaluate_tweet(state: TweetState):\n",
        "    messages = [\n",
        "        SystemMessage(content=\"You are a ruthless, no-laugh-given Twitter critic.\"),\n",
        "        HumanMessage(content=f\"\"\"\n",
        "Evaluate the following tweet:\n",
        "\n",
        "Tweet: \"{state['tweet']}\"\n",
        "\n",
        "Criteria:\n",
        "1. Originality\n",
        "2. Humor\n",
        "3. Punchiness\n",
        "4. Virality\n",
        "5. Format (not Q&A, under 280 chars)\n",
        "\n",
        "Auto-reject if:\n",
        "- Q&A format\n",
        "- Over 280 characters\n",
        "- Traditional setup–punchline jokes\n",
        "- Weak generic endings\n",
        "\n",
        "Respond ONLY in structured format.\n",
        "\"\"\")\n",
        "    ]\n",
        "\n",
        "    response = structured_evaluator_llm.invoke(messages)\n",
        "    return {\n",
        "        \"evaluation\": response.evaluation,\n",
        "        \"feedback\": response.feedback,\n",
        "        \"feedback_history\": [response.feedback],\n",
        "    }\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Step 7: Optimization Node\n",
        "\n",
        "Responsibility:\n",
        "\n",
        "* Rewrite tweet using critic feedback\n",
        "* Increment iteration counter\n",
        "\n",
        "```python\n",
        "def optimize_tweet(state: TweetState):\n",
        "    messages = [\n",
        "        SystemMessage(content=\"You punch up tweets for virality and humor.\"),\n",
        "        HumanMessage(content=f\"\"\"\n",
        "Improve the tweet based on this feedback:\n",
        "\"{state['feedback']}\"\n",
        "\n",
        "Topic: \"{state['topic']}\"\n",
        "Original Tweet:\n",
        "{state['tweet']}\n",
        "\n",
        "Rules:\n",
        "- Stay under 280 characters\n",
        "- Avoid Q&A style\n",
        "\"\"\")\n",
        "    ]\n",
        "\n",
        "    response = optimizer_llm.invoke(messages).content\n",
        "    return {\n",
        "        \"tweet\": response,\n",
        "        \"iteration\": state[\"iteration\"] + 1,\n",
        "        \"tweet_history\": [response],\n",
        "    }\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Step 8: Routing Logic (Loop Control)\n",
        "\n",
        "Purpose:\n",
        "\n",
        "* Stop when approved\n",
        "* Stop when max iterations reached\n",
        "\n",
        "```python\n",
        "def route_evaluation(state: TweetState):\n",
        "    if state[\"evaluation\"] == \"approved\" or state[\"iteration\"] >= state[\"max_iteration\"]:\n",
        "        return \"approved\"\n",
        "    return \"needs_improvement\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Step 9: Build the LangGraph Workflow\n",
        "\n",
        "![Image](https://miro.medium.com/v2/resize%3Afit%3A1200/1%2AWK2y_TTKVa0bxbC_A11tWw.png)\n",
        "\n",
        "![Image](https://images.squarespace-cdn.com/content/v1/6508aa0576c883057e96d23c/415ab2a4-782d-458c-b45f-000ed0c34f62/16%2BSystems%2BDesign%2C%2Bor%2BHow%2Bto%2BMake%2BLLMs%2BPart%2Bof%2Ba%2BFeedback%2BLoop%2B%282%29.png)\n",
        "\n",
        "```python\n",
        "graph = StateGraph(TweetState)\n",
        "\n",
        "graph.add_node(\"generate\", generate_tweet)\n",
        "graph.add_node(\"evaluate\", evaluate_tweet)\n",
        "graph.add_node(\"optimize\", optimize_tweet)\n",
        "\n",
        "graph.add_edge(START, \"generate\")\n",
        "graph.add_edge(\"generate\", \"evaluate\")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    \"evaluate\",\n",
        "    route_evaluation,\n",
        "    {\"approved\": END, \"needs_improvement\": \"optimize\"},\n",
        ")\n",
        "\n",
        "graph.add_edge(\"optimize\", \"evaluate\")\n",
        "\n",
        "workflow = graph.compile()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Step 10: Run the Workflow\n",
        "\n",
        "```python\n",
        "initial_state = {\n",
        "    \"topic\": \"srhberhb\",\n",
        "    \"iteration\": 1,\n",
        "    \"max_iteration\": 5,\n",
        "}\n",
        "\n",
        "result = workflow.invoke(initial_state)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Step 11: Inspect Results\n",
        "\n",
        "Final approved tweet:\n",
        "\n",
        "```python\n",
        "result[\"tweet\"]\n",
        "```\n",
        "\n",
        "Full iteration history:\n",
        "\n",
        "```python\n",
        "for tweet in result[\"tweet_history\"]:\n",
        "    print(tweet)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Mental Model (Concise)\n",
        "\n",
        "* LangGraph loops are **graph edges**, not Python loops\n",
        "* Evaluation is the decision gate\n",
        "* State reducers preserve full history\n",
        "* Iteration limits are mandatory for safety\n",
        "* Structured output enables deterministic control flow\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n0kYU2ZSN55o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "frhsDN7BN-ih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}