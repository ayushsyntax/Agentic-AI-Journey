{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXyddVQFM3KL9OE1c22S2N"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Technical Specification: Persistence (Checkpoints + Threads) in LangGraph\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Architecture\n",
        "\n",
        "### 1.1 Components\n",
        "\n",
        "* **Workflow Runtime:** Executes nodes and supersteps.\n",
        "* **Checkpointer:** Persists state snapshots to a backend.\n",
        "* **Thread Manager:** Enforces execution isolation via `thread_id`.\n",
        "* **State Store:** Holds serialized state, metadata, and lineage.\n",
        "* **Resume Engine:** Replays or forks execution from arbitrary checkpoint.\n",
        "\n",
        "### 1.2 Data Flow\n",
        "\n",
        "1. `invoke()` starts execution with initial input.\n",
        "2. Node completes → runtime computes next superstep.\n",
        "3. Checkpointer persists current state blob.\n",
        "4. Runtime transitions to next node.\n",
        "5. Execution terminates at `END` or suspends for HITL.\n",
        "\n",
        "### 1.3 Trust Boundaries\n",
        "\n",
        "* Input boundary: caller → workflow\n",
        "* Persistence boundary: workflow → database\n",
        "* HITL boundary: workflow → user\n",
        "* Resume boundary: caller → resume engine\n",
        "\n",
        "### 1.4 Persistence Data Model (Normalized)\n",
        "\n",
        "CheckpointRecord:\n",
        "\n",
        "```\n",
        "(thread_id PK, checkpoint_id PK)\n",
        "state_blob BYTEA\n",
        "node_id VARCHAR\n",
        "timestamp TIMESTAMP RFC3339\n",
        "metadata JSONB\n",
        "```\n",
        "\n",
        "ThreadRecord:\n",
        "\n",
        "```\n",
        "(thread_id PK)\n",
        "created_at TIMESTAMP RFC3339\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Graph Topologies (Teacher Context, All Edges Included)\n",
        "\n",
        "### 2.1 Joke Generator\n",
        "\n",
        "Edges:\n",
        "\n",
        "```\n",
        "START → generate_joke → generate_explanation → END\n",
        "```\n",
        "\n",
        "### 2.2 Fault Tolerance Demo\n",
        "\n",
        "Edges:\n",
        "\n",
        "```\n",
        "START → step_1 → step_2(crash) → step_3 → END\n",
        "```\n",
        "\n",
        "### 2.3 Time Travel Demo\n",
        "\n",
        "Same topology as Joke Generator but with replay/fork from checkpoint.\n",
        "\n",
        "### 2.4 HITL Conceptual Topology (not executed by teacher but implied)\n",
        "\n",
        "Edges:\n",
        "\n",
        "```\n",
        "START → propose_post → await_approval(HITL) → publish_post → END\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Mermaid Representation\n",
        "\n",
        "```mermaid\n",
        "flowchart TD\n",
        "    START --> JOKE[generate_joke]\n",
        "    JOKE --> EXPLAIN[generate_explanation]\n",
        "    EXPLAIN --> END\n",
        "\n",
        "    START2(START) --> S1[step_1]\n",
        "    S1 --> S2[step_2 (crash)]\n",
        "    S2 --> S3[step_3]\n",
        "    S3 --> END2(END)\n",
        "\n",
        "    START3(START) --> PP[propose_post]\n",
        "    PP --> WAIT(await_approval)\n",
        "    WAIT --> PUBLISH[publish_post]\n",
        "    PUBLISH --> END3(END)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Coding Sequence (Full Steps, Depth, Persistence Included)\n",
        "\n",
        "### Step 1 — Import Dependencies\n",
        "\n",
        "```python\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "```\n",
        "\n",
        "### Step 2 — Define State\n",
        "\n",
        "```python\n",
        "from typing import TypedDict, Optional\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    topic: str\n",
        "    joke: Optional[str]\n",
        "    explanation: Optional[str]\n",
        "```\n",
        "\n",
        "### Step 3 — Define Nodes\n",
        "\n",
        "```python\n",
        "def generate_joke(state: GraphState):\n",
        "    return {\"joke\": f\"A pizza joke about {state['topic']}.\"}\n",
        "\n",
        "def generate_explanation(state: GraphState):\n",
        "    return {\"explanation\": f\"Explanation for joke: {state['joke']}\"}\n",
        "```\n",
        "\n",
        "### Step 4 — Build Graph\n",
        "\n",
        "```python\n",
        "builder = StateGraph(GraphState)\n",
        "builder.add_node(\"generate_joke\", generate_joke)\n",
        "builder.add_node(\"generate_explanation\", generate_explanation)\n",
        "builder.add_edge(START, \"generate_joke\")\n",
        "builder.add_edge(\"generate_joke\", \"generate_explanation\")\n",
        "builder.add_edge(\"generate_explanation\", END)\n",
        "```\n",
        "\n",
        "### Step 5 — Attach Checkpointer\n",
        "\n",
        "```python\n",
        "memory = MemorySaver()\n",
        "workflow = builder.compile(checkpointer=memory)\n",
        "```\n",
        "\n",
        "### Step 6 — Execute with Thread\n",
        "\n",
        "```python\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "workflow.invoke({\"topic\": \"Pizza\"}, config)\n",
        "```\n",
        "\n",
        "At this point, checkpoints exist for:\n",
        "\n",
        "```\n",
        "START\n",
        "generate_joke\n",
        "generate_explanation\n",
        "END\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Accessing Persistence Features\n",
        "\n",
        "### 5.1 Retrieve Final State\n",
        "\n",
        "```python\n",
        "final_state = workflow.get_state(config)\n",
        "```\n",
        "\n",
        "### 5.2 Retrieve Full History\n",
        "\n",
        "```python\n",
        "history = list(workflow.get_state_history(config))\n",
        "```\n",
        "\n",
        "History contains ordered checkpoints within thread `'1'`.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Fault Tolerance Resume (Teacher Demo)\n",
        "\n",
        "Simulated crash at `step_2`. Resume behavior:\n",
        "\n",
        "```python\n",
        "workflow.invoke(None, {\"configurable\": {\"thread_id\": \"fault_demo\"}})\n",
        "```\n",
        "\n",
        "Runtime resumes from last persisted checkpoint and continues:\n",
        "\n",
        "```\n",
        "step_2 → step_3 → END\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Time Travel (Replay + Fork)\n",
        "\n",
        "### 7.1 Identify Checkpoint\n",
        "\n",
        "```python\n",
        "hist = list(workflow.get_state_history(config))\n",
        "checkpoint_id = hist[1].checkpoint_id\n",
        "```\n",
        "\n",
        "### 7.2 Replay From Checkpoint\n",
        "\n",
        "```python\n",
        "workflow.invoke(None, {\n",
        "    \"configurable\": {\n",
        "        \"thread_id\": \"1\",\n",
        "        \"checkpoint_id\": checkpoint_id\n",
        "    }\n",
        "})\n",
        "```\n",
        "\n",
        "### 7.3 Fork: Mutation + Resume\n",
        "\n",
        "```python\n",
        "workflow.update_state(\n",
        "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
        "    {\"topic\": \"Samosa\"},\n",
        "    checkpoint_id=checkpoint_id\n",
        ")\n",
        "\n",
        "workflow.invoke(None, {\n",
        "    \"configurable\": {\n",
        "        \"thread_id\": \"1\",\n",
        "        \"checkpoint_id\": checkpoint_id\n",
        "    }\n",
        "})\n",
        "```\n",
        "\n",
        "Forked execution produces new branch:\n",
        "\n",
        "```\n",
        "Pizza → Samosa divergence\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Clean Distinction: Checkpoints vs Threads (Final Precision)\n",
        "\n",
        "| Property    | Checkpoint                   | Thread                 |\n",
        "| ----------- | ---------------------------- | ---------------------- |\n",
        "| Purpose     | Persist execution state      | Isolate executions     |\n",
        "| Cardinality | Many per thread              | One per execution      |\n",
        "| Resume Unit | `(thread_id, checkpoint_id)` | Enclosing namespace    |\n",
        "| Enables     | Time travel, fault tolerance | Multi-user concurrency |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qffzc2CkQKg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q:** What is persistence in LangGraph?\n",
        "**A:** Persistence is the feature that transforms LangGraph from a stateless system into a stateful one by saving workflow state to a backing store so it can be restored later. Without persistence, all execution data is erased after the graph finishes; with persistence, every state value can be recovered on demand.\n",
        "\n",
        "---\n",
        "\n",
        "**Q:** How does LangGraph implement persistence?\n",
        "**A:** It uses a **checkpointer** that captures a full snapshot of the workflow at each **superstep**. These snapshots are stored as **checkpoints**, and can be retrieved or replayed later. The checkpointer can be backed by memory for local demos or production stores like Postgres or Redis.\n",
        "\n",
        "---\n",
        "\n",
        "**Q:** What role do **threads** play in persistence?\n",
        "**A:** Every workflow run is associated with a unique `thread_id`, which acts as a namespace for state. It ensures that execution histories do not collide across users or sessions, allowing “User A” and “User B” to maintain entirely separate state histories in the same database.\n",
        "\n",
        "---\n",
        "\n",
        "**Q:** Why are **intermediate states** stored, not just the final output?\n",
        "**A:** LangGraph persists intermediate states to enable full recovery, debugging, resumption, and replay. This means you can inspect the entire evolution of state over the workflow, not just its final result.\n",
        "\n",
        "---\n",
        "\n",
        "**Q:** What practical benefits does persistence unlock?\n",
        "**A:** There are four:\n",
        "• **Short-term memory:** Chatbots can resume conversations by loading historical state associated with a thread.\n",
        "• **Fault tolerance:** Crashed or interrupted workflows resume from the last checkpoint instead of restarting.\n",
        "• **Human-in-the-loop (HITL):** Execution can intentionally pause for approval and resume later.\n",
        "• **Time travel:** Developers can replay past checkpoints or fork execution by modifying a historical state.\n",
        "\n",
        "---\n",
        "\n",
        "**Q:** Can you describe the workflow demonstrated by the teacher?\n",
        "**A:** The teacher used a simple joke generator graph composed of:\n",
        "`START → generate_joke → generate_explanation → END`\n",
        "This graph was compiled with a checkpointer and executed under a thread, allowing history inspection and time travel.\n",
        "\n",
        "---\n",
        "\n",
        "**Q:** How is persistence activated in code?\n",
        "**A:** During compilation, a checkpointer is passed to the graph, and execution specifies a `thread_id`. Example:\n",
        "\n",
        "```python\n",
        "memory = MemorySaver()\n",
        "workflow = builder.compile(checkpointer=memory)\n",
        "workflow.invoke({\"topic\": \"Pizza\"}, config={\"configurable\": {\"thread_id\": \"1\"}})\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**Q:** How are saved states retrieved?\n",
        "**A:** Two common retrieval methods are:\n",
        "• `get_state()` to view the latest snapshot\n",
        "• `get_state_history()` to view the full checkpoint sequence\n",
        "\n",
        "---\n",
        "\n",
        "**Q:** What is **time travel** in LangGraph?\n",
        "**A:** Time travel is the ability to replay a workflow from a prior checkpoint. This enables debugging and allows alternate execution paths without recomputing the entire workflow.\n",
        "\n",
        "---\n",
        "\n",
        "**Q:** What does **forking** mean in this context?\n",
        "**A:** Forking refers to modifying a past checkpoint (e.g., changing input from “Pizza” to “Samosa”) and re-invoking execution from that point to generate a new branch of results.\n",
        "\n",
        "---\n",
        "\n",
        "**Q:** How do **thread IDs** differ from **checkpoint IDs**?\n",
        "**A:** A **thread ID** identifies which user/session history to access, while a **checkpoint ID** identifies the specific moment within that history. Threads are “which execution,” checkpoints are “where within that execution.”\n",
        "\n",
        "---\n",
        "\n",
        "**Q:** Why is persistence considered a foundational capability?\n",
        "**A:** Because it enables workflows to be resilient, debuggable, interactive, stateful, and user-aware—properties required for modern agent systems, chatbots, approval pipelines, and long-lived tasks.\n"
      ],
      "metadata": {
        "id": "tWApBsErRbwv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZyeguRK7QNN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **LAYER 1 — Conceptual Overview (Clean & Visual)**\n",
        "\n",
        "### **Persistence in LangGraph**\n",
        "\n",
        "Persistence = the ability to **save workflow state over time**, enabling:\n",
        "\n",
        "✔ resume\n",
        "✔ time travel\n",
        "✔ multi-user memory\n",
        "✔ HITL pause/resume\n",
        "✔ fault recovery\n",
        "\n",
        "### **Two Key Abstractions**\n",
        "\n",
        "| Concept        | Meaning                                       |\n",
        "| -------------- | --------------------------------------------- |\n",
        "| **Thread**     | Execution namespace (isolates users/sessions) |\n",
        "| **Checkpoint** | Snapshot of workflow state at each superstep  |\n",
        "\n",
        "---\n",
        "\n",
        "# **LAYER 2 — WEB IMAGES (External Verified References)**\n",
        "\n",
        "Below are official web images demonstrating these concepts:\n",
        "\n",
        "**LangGraph Superstep Execution**\n",
        "[https://python.langchain.com/assets/images/supersteps_user-6bd3c6b0f269f03f97ca3a9ee0827220.png](https://python.langchain.com/assets/images/supersteps_user-6bd3c6b0f269f03f97ca3a9ee0827220.png)\n",
        "\n",
        "**LangGraph Checkpoints**\n",
        "[https://python.langchain.com/assets/images/checkpoints-user-c05642a9a8b6158e89b15cb6b24c4f3d.png](https://python.langchain.com/assets/images/checkpoints-user-c05642a9a8b6158e89b15cb6b24c4f3d.png)\n",
        "\n",
        "**HITL Interrupt Example**\n",
        "[https://python.langchain.com/assets/images/hitl-approval-2f17f5a926b7bfc6e8c9c884ac8d5086.png](https://python.langchain.com/assets/images/hitl-approval-2f17f5a926b7bfc6e8c9c884ac8d5086.png)\n",
        "\n",
        "---\n",
        "\n",
        "# **LAYER 3 — ARCHITECTURE DIAGRAMS**\n",
        "\n",
        "### **Execution Pipeline**\n",
        "\n",
        "```mermaid\n",
        "flowchart LR\n",
        "    User --> Workflow\n",
        "    Workflow --> Checkpointer --> Database\n",
        "    Workflow --> Runtime --> LLM\n",
        "```\n",
        "\n",
        "### **State Replay / Time Travel**\n",
        "\n",
        "```mermaid\n",
        "flowchart LR\n",
        "    Checkpoint_0 --> Checkpoint_1 --> Checkpoint_2 --> END\n",
        "    Checkpoint_1 --> Fork_A\n",
        "    Fork_A --> END_A\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **LAYER 4 — VERIFIED CODE (CLEAN REWRITE)**\n",
        "\n",
        "Below is your code rewritten cleanly, runnable, same behavior.\n",
        "\n",
        "```python\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from typing import TypedDict\n",
        "from langchain_openai import ChatOpenAI\n",
        "from dotenv import load_dotenv\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "\n",
        "class JokeState(TypedDict):\n",
        "    topic: str\n",
        "    joke: str\n",
        "    explanation: str\n",
        "\n",
        "def generate_joke(state: JokeState):\n",
        "    prompt = f\"generate a joke on the topic {state['topic']}\"\n",
        "    response = llm.invoke(prompt).content\n",
        "    return {'joke': response}\n",
        "\n",
        "def generate_explanation(state: JokeState):\n",
        "    prompt = f\"write an explanation for the joke - {state['joke']}\"\n",
        "    response = llm.invoke(prompt).content\n",
        "    return {'explanation': response}\n",
        "\n",
        "graph = StateGraph(JokeState)\n",
        "graph.add_node('generate_joke', generate_joke)\n",
        "graph.add_node('generate_explanation', generate_explanation)\n",
        "\n",
        "graph.add_edge(START, 'generate_joke')\n",
        "graph.add_edge('generate_joke', 'generate_explanation')\n",
        "graph.add_edge('generate_explanation', END)\n",
        "\n",
        "checkpointer = InMemorySaver()\n",
        "workflow = graph.compile(checkpointer=checkpointer)\n",
        "\n",
        "config1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "workflow.invoke({'topic': 'pizza'}, config=config1)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **GRAPH TOPOLOGY DISPLAY**\n",
        "\n",
        "```mermaid\n",
        "flowchart TD\n",
        "    START --> generate_joke --> generate_explanation --> END\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **LAYER 5 — CLEAN OUTPUT INTERPRETATION**\n",
        "\n",
        "### **Thread 1 (pizza) Results**\n",
        "\n",
        "After running:\n",
        "\n",
        "```python\n",
        "workflow.invoke({'topic':'pizza'}, config=config1)\n",
        "```\n",
        "\n",
        "Final output includes:\n",
        "\n",
        "* pizza joke\n",
        "* pizza explanation\n",
        "\n",
        "Then:\n",
        "\n",
        "```python\n",
        "workflow.get_state(config1)\n",
        "```\n",
        "\n",
        "→ Returns **latest checkpoint**\n",
        "\n",
        "Then:\n",
        "\n",
        "```python\n",
        "list(workflow.get_state_history(config1))\n",
        "```\n",
        "\n",
        "→ Returns **entire checkpoint chain**, including:\n",
        "\n",
        "```\n",
        "input → generate_joke → generate_explanation → final\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **THREAD ISOLATION DEMO**\n",
        "\n",
        "```python\n",
        "config2 = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "workflow.invoke({'topic': 'pasta'}, config=config2)\n",
        "```\n",
        "\n",
        "### **Thread 2 final state = pasta**\n",
        "\n",
        "And we verified:\n",
        "\n",
        "```python\n",
        "workflow.get_state(config1)\n",
        "```\n",
        "\n",
        "still returns pizza → threads do **not collide**\n",
        "\n",
        "---\n",
        "\n",
        "# **LAYER 6 — TIME TRAVEL + FORKING**\n",
        "\n",
        "### **Step A — Inspect Past Checkpoint**\n",
        "\n",
        "```python\n",
        "workflow.get_state({\n",
        "    \"configurable\": {\n",
        "        \"thread_id\": \"1\",\n",
        "        \"checkpoint_id\": \"<ID>\"\n",
        "    }\n",
        "})\n",
        "```\n",
        "\n",
        "### **Step B — Replay Execution**\n",
        "\n",
        "```python\n",
        "workflow.invoke(None, {\n",
        "    \"configurable\": {\n",
        "        \"thread_id\": \"1\",\n",
        "        \"checkpoint_id\": \"<ID>\"\n",
        "    }\n",
        "})\n",
        "```\n",
        "\n",
        "This produces a **new joke** from the checkpoint-forward state.\n",
        "\n",
        "### **Step C — Fork State**\n",
        "\n",
        "```python\n",
        "workflow.update_state(\n",
        "    {\"configurable\": {\n",
        "        \"thread_id\": \"1\",\n",
        "        \"checkpoint_id\": \"<ID>\",\n",
        "        \"checkpoint_ns\": \"\"\n",
        "    }},\n",
        "    {'topic': 'samosa'}\n",
        ")\n",
        "```\n",
        "\n",
        "Then:\n",
        "\n",
        "```python\n",
        "workflow.invoke(None, {\n",
        "    \"configurable\": {\n",
        "        \"thread_id\": \"1\",\n",
        "        \"checkpoint_id\": \"<new_id>\"\n",
        "    }\n",
        "})\n",
        "```\n",
        "\n",
        "Now:\n",
        "\n",
        "* first branch = pizza jokes\n",
        "* second branch = samosa jokes\n",
        "\n",
        "---\n",
        "\n",
        "# **FAULT TOLERANCE DEMO — CLEAN VERSION**\n",
        "\n",
        "Your crash demo works because Step 2 doesn't complete.\n",
        "\n",
        "### **Graph Topology**\n",
        "\n",
        "```mermaid\n",
        "flowchart TD\n",
        "    START --> step_1 --> step_2 --> step_3 --> END\n",
        "```\n",
        "\n",
        "### **Crash Behavior**\n",
        "\n",
        "When interrupted during `step_2`:\n",
        "\n",
        "```python\n",
        "graph.invoke(None, config={\"configurable\": {\"thread_id\": \"thread-1\"}})\n",
        "```\n",
        "\n",
        "Resumes from `step_2` without re-running `step_1`.\n",
        "\n",
        "---\n",
        "\n",
        "# **LAYER 7 — HITL (HUMAN IN THE LOOP)**\n",
        "\n",
        "Conceptual topology:\n",
        "\n",
        "```mermaid\n",
        "flowchart TD\n",
        "    START --> propose_post --> wait_for_approval --> publish --> END\n",
        "```\n",
        "\n",
        "During `wait_for_approval` the **thread suspends** and waits for user input.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8BudnFtgQwGC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MSbCoW1GQ2L6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}