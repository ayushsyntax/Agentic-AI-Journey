{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMM+1ANk0rPknXnqy/vNaJn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Transition from Volatile RAM Checkpoints to Persistent SQLite Checkpoints in LangGraph\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# 1. Architecture\n",
        "\n",
        "## 1.1 System Components\n",
        "\n",
        "* LangGraph runtime engine (checkpointing + node scheduling)\n",
        "* SQLite persistence checkpointing using `SqliteSaver`\n",
        "* Streamlit UI front-end\n",
        "* OpenAI-compatible chat LLM backend\n",
        "* Local storage filesystem for `chatbot.db`\n",
        "\n",
        "## 1.2 Dataflow\n",
        "\n",
        "User input → Streamlit UI → LangGraph → Chat Node → LLM Invocation → Response → Checkpoint persisted to SQLite → Resume Execution\n",
        "\n",
        "## 1.3 Trust Boundaries\n",
        "\n",
        "* UI boundary: User input enters application (untrusted)\n",
        "* LLM boundary: Prompts and responses (semi-trusted)\n",
        "* Database boundary: Local SQLite store (trusted)\n",
        "* OS boundary: Local filesystem (trusted)\n",
        "\n",
        "Input validation performed at the UI boundary. LLM outputs are treated as untrusted content and sanitized for rendering.\n",
        "\n",
        "## 1.4 Diagram (Mermaid)\n",
        "\n",
        "```mermaid\n",
        "flowchart TD\n",
        "    UI[Streamlit UI] -->|text input| LG[LangGraph Engine]\n",
        "    LG --> DB[(SQLite Checkpoints)]\n",
        "    LG --> LLM[Chat LLM]\n",
        "    LLM --> LG\n",
        "    LG --> UI\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# 2. Implementation\n",
        "\n",
        "## 2.1 Dependencies (Pinned)\n",
        "\n",
        "```\n",
        "python==3.11.8\n",
        "langgraph-checkpoint-sqlite==0.0.3\n",
        "langchain-openai==0.2.7\n",
        "streamlit==1.36.0\n",
        "sqlite3 (stdlib)\n",
        "uuid (stdlib)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 2.2 Backend: Persistent SQLite Checkpoints\n",
        "\n",
        "```python\n",
        "# backend.py\n",
        "\n",
        "import sqlite3\n",
        "from typing import TypedDict, Annotated, List\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "class ChatState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], add_messages]\n",
        "\n",
        "def chat_node(state: ChatState) -> dict:\n",
        "    messages = state[\"messages\"]\n",
        "    if not isinstance(messages, list):\n",
        "        raise TypeError(\"messages must be a list\")\n",
        "    llm = ChatOpenAI()\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "conn = sqlite3.connect(\"chatbot.db\", check_same_thread=False)\n",
        "checkpointer = SqliteSaver(conn)\n",
        "\n",
        "graph = StateGraph(ChatState)\n",
        "graph.add_node(\"chat_node\", chat_node)\n",
        "graph.add_edge(START, \"chat_node\")\n",
        "graph.add_edge(\"chat_node\", END)\n",
        "chatbot = graph.compile(checkpointer=checkpointer)\n",
        "\n",
        "def retrieve_all_threads() -> list:\n",
        "    result = set()\n",
        "    for cp in checkpointer.list(None):\n",
        "        result.add(cp.config[\"configurable\"][\"thread_id\"])\n",
        "    return list(result)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 2.3 Frontend (Streamlit Integration)\n",
        "\n",
        "```python\n",
        "# app.py\n",
        "\n",
        "import streamlit as st\n",
        "import uuid\n",
        "from typing import List\n",
        "from langchain_core.messages import HumanMessage\n",
        "from backend import chatbot, retrieve_all_threads\n",
        "\n",
        "def generate_thread_id() -> str:\n",
        "    return str(uuid.uuid4())\n",
        "\n",
        "def validate_thread_id(value: str) -> str:\n",
        "    if not isinstance(value, str):\n",
        "        raise ValueError(\"thread_id must be str\")\n",
        "    return value\n",
        "\n",
        "def load_conversation(thread_id: str) -> List[dict]:\n",
        "    state = chatbot.get_state(config={\"configurable\": {\"thread_id\": thread_id}})\n",
        "    msgs = state.values.get(\"messages\", [])\n",
        "    result = []\n",
        "    for msg in msgs:\n",
        "        role = \"user\" if isinstance(msg, HumanMessage) else \"assistant\"\n",
        "        result.append({\"role\": role, \"content\": msg.content})\n",
        "    return result\n",
        "\n",
        "if \"thread_id\" not in st.session_state:\n",
        "    st.session_state[\"thread_id\"] = generate_thread_id()\n",
        "if \"chat_threads\" not in st.session_state:\n",
        "    st.session_state[\"chat_threads\"] = retrieve_all_threads()\n",
        "if \"message_history\" not in st.session_state:\n",
        "    st.session_state[\"message_history\"] = []\n",
        "\n",
        "st.sidebar.title(\"LangGraph Chatbot\")\n",
        "\n",
        "if st.sidebar.button(\"New Chat\"):\n",
        "    new_id = generate_thread_id()\n",
        "    st.session_state[\"thread_id\"] = new_id\n",
        "    st.session_state[\"chat_threads\"].append(new_id)\n",
        "    st.session_state[\"message_history\"] = []\n",
        "\n",
        "st.sidebar.header(\"Conversations\")\n",
        "\n",
        "for tid in st.session_state[\"chat_threads\"][::-1]:\n",
        "    if st.sidebar.button(tid):\n",
        "        validate_thread_id(tid)\n",
        "        st.session_state[\"thread_id\"] = tid\n",
        "        st.session_state[\"message_history\"] = load_conversation(tid)\n",
        "\n",
        "for m in st.session_state[\"message_history\"]:\n",
        "    with st.chat_message(m[\"role\"]):\n",
        "        st.text(m[\"content\"])\n",
        "\n",
        "user_input = st.chat_input(\"Type here\")\n",
        "\n",
        "if user_input:\n",
        "    st.session_state[\"message_history\"].append({\"role\": \"user\", \"content\": user_input})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.text(user_input)\n",
        "\n",
        "    config = {\n",
        "        \"configurable\": {\"thread_id\": st.session_state[\"thread_id\"]},\n",
        "        \"metadata\": {\"thread_id\": st.session_state[\"thread_id\"]},\n",
        "        \"run_name\": \"chat_turn\",\n",
        "    }\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        output = st.write_stream(\n",
        "            chunk.content for chunk, _meta in chatbot.stream(\n",
        "                {\"messages\": [HumanMessage(content=user_input)]},\n",
        "                config=config,\n",
        "                stream_mode=\"messages\"\n",
        "            )\n",
        "        )\n",
        "    st.session_state[\"message_history\"].append({\"role\": \"assistant\", \"content\": output})\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "1qthmV9VS6U7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6v3vt5mSswK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## 1. Difference between a checkpoint and a message buffer\n",
        "\n",
        "A checkpoint is a persisted snapshot of graph execution state (messages, node outputs, config, execution metadata). It enables full resumption of execution at deterministic boundaries. A message buffer is a temporary in-memory collection of user/agent messages used to construct the prompt and produce the next model invocation. The checkpoint survives process restarts; the buffer does not.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. How LangGraph schedules nodes and resolves state\n",
        "\n",
        "LangGraph executes via state machines. Nodes define transformation functions over a typed state dictionary. Execution proceeds through edges defined between nodes until termination conditions are met. Each node invocation receives immutable state and returns a deterministic diff to be merged. This produces a linear or branching state evolution depending on graph topology. Scheduling completes when the END marker is reached or when multiple branches converge. Checkpoints capture state after “supersteps.”\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Durability guarantees of SQLite vs PostgreSQL\n",
        "\n",
        "SQLite uses a single-file ACID-compliant storage engine with transactional semantics and journaling. Durability is local to the filesystem with no built-in replication. PostgreSQL implements WAL (write-ahead-logging) with background flush, crash recovery, multi-process concurrency, replication (streaming, logical, synchronous), multi-region failover, and hot backups. PostgreSQL supports stronger durability guarantees in distributed deployments.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Why `check_same_thread=False` is required\n",
        "\n",
        "The SQLite Python driver restricts DB operations to the thread that created the connection. LangGraph may handle different conversation threads via multiple UI or scheduler threads. Disabling the thread check allows the same connection object to be shared across threads. Without it, calls during checkpoint writes raise `ProgrammingError`.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Thread isolation in multi-agent chat systems\n",
        "\n",
        "Isolation is achieved by namespacing memory and state by a thread identifier. Each thread’s checkpoint log forms a separate execution lineage so concurrent interactions do not pollute each other’s context. Isolation can be at the key level (thread_id), row level, schema level, or database level.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. ACID and how SQLite implements it\n",
        "\n",
        "ACID = Atomicity, Consistency, Isolation, Durability. SQLite implements it using journaling (rollback journal or WAL), coarse-grained write locks, and atomic filesystem operations. On crash, uncommitted writes are discarded via journal replay. Durability is guaranteed when synchronous=FULL and fsync completes before commit returns.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Recovery from partial checkpoint writes\n",
        "\n",
        "During a partial write or crash, checkpointing replays the journal. Committed transactions in WAL are applied during recovery. Uncommitted frames are discarded. For rollback journal mode, the original page content is restored from the rollback journal, preserving pre-transaction state.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. WAL vs rollback journal tradeoff\n",
        "\n",
        "Rollback journal copies original pages before writing new ones. WAL appends changes sequentially to a WAL file and checkpoints back to the main DB later. WAL improves concurrency (multiple readers + single writer), write throughput, and reduces page copying. Rollback journal has simpler guarantees but lower concurrency.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Schema-less JSON storage for message envelopes\n",
        "\n",
        "Message content can be encoded as JSON text within a TEXT or BLOB column. This avoids migration churn as envelope shape evolves. Retrieval is done via application-level parsing. PostgreSQL would additionally offer JSONB indexing, which SQLite lacks natively.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Migration strategy SQLite → PostgreSQL\n",
        "\n",
        "Typical pipeline:\n",
        "\n",
        "1. schema creation in PostgreSQL\n",
        "2. extraction from SQLite\n",
        "3. transformation of JSON envelopes\n",
        "4. load into PostgreSQL\n",
        "5. update application to point at new DSN\n",
        "6. cutover with freeze period or dual-write\n",
        "7. decommission SQLite after validation\n",
        "\n",
        "Node checkpoint format does not need to change assuming envelopes remain JSON-compatible.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SIhVXyluTTar"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "04FXactsTXtg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}